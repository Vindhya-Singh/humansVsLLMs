{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "from openai import OpenAI\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OpenAI API Key (Replace with your actual API key)\n",
    "client = OpenAI(\n",
    "api_key = \"your api key here\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column = \"define inclusion dimension here\"\n",
    "model = 'define the model here'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input and output file paths\n",
    "INPUT_EXCEL = \"/projects/humansVsLLMs/results/sociodemographic_prompts.xlsx\"  # Excel file containing prompts\n",
    "OUTPUT_CSV = f\"/projects/humansVsLLMs/results/4-Dimensions-3Shot-GeneratedResponses/generated_responses_{column}_{model}.csv\"  # CSV file to store responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add the Prompt from the developed script with the demographic data to create the final prompt\n",
    "prompt_uniqueness =\"\"\"Fostering employee's uniqueness is characterized by supporting employees as individuals, recognizing their individual differences, empowering them, and contributing to their learning and development.Uniqueness includes four categories \n",
    "                    focusing on the leader-employee relationship. The first category, supporting employees as individuals,involves leaders paying attention to employees' feelings, offering guidance, and being available. The second category, promoting diversity,\n",
    "                    highlights recognizing and valuing employees' unique characteristics and helping them contribute effectively. The third category, empowering employees, involves enabling employees to take independent actions, collaborating during\n",
    "                    decision-making, and encouraging idea-sharing about work execution. Finally, employees' learning and development (L&D), emphasizes providing opportunities for growth, offering feedback, guiding through mistakes, \n",
    "                    and focusing on training to enhance strengths and address weaknesses. Here are examples of SMART goals:\n",
    "                    * I will offer guidance to [team member] at our meeting today.\n",
    "                    * I will work with [team member] to establish contact with at least five minority driven businesses by the end of this week.\n",
    "                    * I will meet [team member] to prioritize and schedule trainings for them after lunch today.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_belong = \"\"\"Strengthening belongingness within your team is characterized by ensuring equity, building relationships, and sharing decision making.Belongingness focuses on relationships between leaders and team members. \n",
    "                Leaders can enhance it by ensuring equity through demonstrating moral behavior, making unbiased judgments, fairly distributing rewards, and ensuring fair representation of team members. Building relationships requires leaders to develop \n",
    "                strong connections with the team and encourages positive interactions among team members. Sharing decision-making involves including employees' opinions in decisions, explaining the reasoning behind practices, and collaborating with \n",
    "                employees rather than merely directing them. Here are examples of SMART goals:\n",
    "                * I will ensure everyone has a chance to speak in today's team meeting.\n",
    "                * I will organize a team building event till the end of this week to strengthen belongingness.\n",
    "                * I will consult with team members and build consensus on hiring a new team member this afternoon.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_appreciation = \"\"\"Showing appreciation to your team and team members is characterized by recognizing their efforts and contributions. Showing appreciation to your team members focuses on your responses to achievements and efforts. Leaders demonstrate this by noticing efforts, affirming contributions, and praising achievements at both individul and team levels.\n",
    "                        Here are some example of showing appreciation to your team members:\n",
    "                        * I will affirm contributions of our new hire for the project at the team-meeting today.\n",
    "                        * I will praise the technical achievements of [team member] at today's meeting.\n",
    "                        * I will develop an ‘Employee of the Month’ initiative by end of the day today.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_orgeefforts = \"\"\"Supporting inclusive organizational efforts is characterized by being open to organizational change and promoting organizational mission  on inclusion. Supporting inclusive organizational efforts involves leaders actively engaging with organizational goals. Leaders should be open to change and promote innovative ideas to foster inclusion. Leaders who advocate for the organization's mission on inclusion communicate its importance, work towards establishing a diverse workforce, and align organizational practices with inclusive values. \n",
    "                        Here are some examples of supporting organizational efforts:\n",
    "                        * I will identify and document at least three new opportunities to improve inclusive practices before lunch today.\n",
    "                        * I will communicate with [team member] how inclusion is related to our mission and vision in today's meeting.\n",
    "                        * I will explain [team member] how organizational inclusive practices are aligned with our team's goals at today's coffee-break.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the Excel file\n",
    "try:\n",
    "    df = pd.read_excel(INPUT_EXCEL)\n",
    "    if column not in df.columns:\n",
    "        raise ValueError(\"The Excel file must have a column named 'Prompt'.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error reading Excel file: {e}\")\n",
    "    exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get ChatGPT response\n",
    "def get_chatgpt_response(prompt):\n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-4o-mini\",\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "        )\n",
    "        return response.choices[0].message.content.strip()\n",
    "    except Exception as e:\n",
    "        return f\"Error: {e}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Please install OpenAI SDK first: `pip3 install openai`\n",
    "client = OpenAI(api_key=\"your_key_here\", base_url=\"https://api.deepseek.com\")\n",
    "def get_deepseek_response(prompt):\n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"deepseek-r1\",\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "            stream=False\n",
    "        )\n",
    "        return response.choices[0].message.content\n",
    "    except Exception as e:\n",
    "        return f\"Error: {e}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google import genai\n",
    "client = genai.Client(api_key=\"your_key_here\")\n",
    "\n",
    "def get_gemini_response(prompt):\n",
    "    try:\n",
    "        response = client.models.generate_content(\n",
    "            model=\"gemini-2.0-flash\", contents=prompt)\n",
    "        return response.text\n",
    "    except Exception as e:\n",
    "        return f\"Error: {e}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cohere\n",
    "# Get your free API key here: https://dashboard.cohere.com/api-keys\n",
    "co = cohere.ClientV2(\"your_key_here\") # paid\n",
    "def get_cohere_response(prompt):\n",
    "    try:\n",
    "        response = co.chat(\n",
    "        model=\"command-a-03-2025\",\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "    )\n",
    "        return response.message.content[0].text\n",
    "    except Exception as e:\n",
    "        return f\"Error: {e}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "client = OpenAI(\n",
    "    # If environment variables are not configured, replace the following line with: api_key=\"sk-xxx\",\n",
    "    api_key=os.getenv(\"your_key_here\"), \n",
    "    base_url=\"https://dashscope-intl.aliyuncs.com/compatible-mode/v1\",\n",
    ")\n",
    "def get_qwen_response(prompt):\n",
    "    try:\n",
    "        completion = client.chat.completions.create(\n",
    "            model=\"qwen-plus\", # This example uses qwen-plus. You can change the model name as needed. Model list: https://www.alibabacloud.com/help/en/model-studio/getting-started/models\n",
    "            messages=[{'role': 'user', 'content': prompt}],\n",
    "            )\n",
    "        return completion.choices[0].message.content.strip()\n",
    "    except Exception as e:\n",
    "        return f\"Error: {e}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mistralai import Mistral\n",
    "\n",
    "api_key = \"your_key_here\"\n",
    "\n",
    "def get_mistral_response(prompt):\n",
    "    model = \"mistral-large-latest\"\n",
    "    try:\n",
    "        client = Mistral(api_key=api_key)\n",
    "\n",
    "        chat_response = client.chat.complete(\n",
    "            model= model,\n",
    "            messages = [\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": prompt,\n",
    "                },\n",
    "            ]\n",
    "        )\n",
    "        return chat_response.choices[0].message.content\n",
    "    except Exception as e:\n",
    "        return f\"Error: {e}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(\n",
    "    # This is the default and can be omitted\n",
    "    api_key= \"your_key_here\",\n",
    "    base_url=\"https://api.llmapi.com/\"\n",
    ")\n",
    "\n",
    "def get_llama_response(prompt):\n",
    "    try:\n",
    "        chat_completion = client.chat.completions.create(\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "            model=\"llama-3.3-70b\"\n",
    "        )\n",
    "        return chat_completion.choices[0].message.content.strip()\n",
    "\n",
    "    except Exception as e:\n",
    "        return f\"Error: {e}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process each prompt and store responses\n",
    "responses = []\n",
    "for index, row in df.iterrows():\n",
    "    prompt = str(row[column]).strip() + prompt_orgeefforts\n",
    "    # print(prompt)\n",
    "    response = get_chatgpt_response(prompt)\n",
    "    responses.append({\"Prompt\": prompt, \"Response\": response})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save responses to CSV\n",
    "output_df = pd.DataFrame(responses)\n",
    "print(output_df.shape)\n",
    "output_df.to_csv(OUTPUT_CSV, index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "emnlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
