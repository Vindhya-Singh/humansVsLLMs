{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Warriner et al. VAD Lexicon\n",
    "vad_lexicon = pd.read_csv('https://raw.githubusercontent.com/cwlab-vu/VAD-lexicon/master/Warriner_et_al.csv')\n",
    "vad_lexicon = vad_lexicon.set_index('Word')  # Faster lookup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load your DataFrame\n",
    "model = 'qwen'\n",
    "path = '/projects/humansVsLLMs/results/3-shot-generated-responses'\n",
    "df = pd.read_csv(f\"{path}/{model}_generated_responses.csv\")  # Replace with your file\n",
    "texts = df['Response'].dropna().astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/projects/humansVsLLMs/data'\n",
    "df = pd.read_csv(f\"{path}/goals_leader_with_demographics.csv\")  # Replace with your file\n",
    "texts = df['Leader_Action_Plans'].dropna().astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize cumulative scores\n",
    "valence_sum = 0\n",
    "arousal_sum = 0\n",
    "dominance_sum = 0\n",
    "word_count = 0\n",
    "file_path = '/projects/humansVsLLMs/plots'\n",
    "# Go through each row\n",
    "for text in texts:\n",
    "    tokens = word_tokenize(text.lower())\n",
    "    for token in tokens:\n",
    "        if token in vad_lexicon.index:\n",
    "            valence_sum += vad_lexicon.loc[token, 'V.Mean.Sum']\n",
    "            arousal_sum += vad_lexicon.loc[token, 'A.Mean.Sum']\n",
    "            dominance_sum += vad_lexicon.loc[token, 'D.Mean.Sum']\n",
    "            word_count += 1\n",
    "\n",
    "# Calculate averages\n",
    "valence_avg = valence_sum / word_count if word_count > 0 else 0\n",
    "arousal_avg = arousal_sum / word_count if word_count > 0 else 0\n",
    "dominance_avg = dominance_sum / word_count if word_count > 0 else 0\n",
    "\n",
    "# Create results DataFrame\n",
    "results = pd.DataFrame({\n",
    "    'Dimension': ['Valence', 'Arousal', 'Dominance'],\n",
    "    'Average Score': [valence_avg, arousal_avg, dominance_avg]\n",
    "})\n",
    "\n",
    "# --------- Visualize & Save as SVG ---------\n",
    "plt.figure(figsize=(8, 6))\n",
    "plot = sns.barplot(x='Dimension', y='Average Score', data=results, palette='Set2')\n",
    "plt.title(\"Average Valence, Arousal, and Dominance Scores\")\n",
    "plt.ylim(0, 9)  # VAD scores typically range from 1 to 9\n",
    "\n",
    "# Save as SVG\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"{file_path}/{model}_vad_scores.svg\", format='svg')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "print(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Step 1: Read .txt file as vad_df (assuming tab-delimited or space-delimited)\n",
    "vad_df = pd.read_csv(\"/projects/humansVsLLMs/data/VAD/NRC-VAD-Lexicon-v2.1/NRC-VAD-Lexicon-v2.1/NRC-VAD-Lexicon-v2.1.txt\", sep=\"\\t\", on_bad_lines='skip')  # or sep=\"\\t\" depending on the format\n",
    "vad_df.columns = ['term', 'valence', 'arousal', 'dominance']\n",
    "vad_df['term'] = vad_df['term'].str.lower()\n",
    "\n",
    "# Step 2: Read .csv file as rll_df\n",
    "rll_df = pd.read_csv(\"/projects/humansVsLLMs/data/data_leaders_with_demographics_semantics.csv\")\n",
    "rll_df = rll_df[~rll_df['GenderIdentity'].isin(['Male', 'Female'])]\n",
    "print(rll_df.shape)\n",
    "# Step 3: Define function to extract VAD scores\n",
    "def extract_vad_scores(text, vad_lookup):\n",
    "    if pd.isna(text):\n",
    "        return np.nan, np.nan, np.nan\n",
    "\n",
    "    words = text.lower().split()\n",
    "    matched = vad_lookup[vad_lookup['term'].isin(words)]\n",
    "    \n",
    "    if matched.empty:\n",
    "        return np.nan, np.nan, np.nan\n",
    "    else:\n",
    "        return (\n",
    "            matched['valence'].mean(),\n",
    "            matched['arousal'].mean(),\n",
    "            matched['dominance'].mean()\n",
    "        )\n",
    "\n",
    "# Step 4: Apply the function row-wise\n",
    "scores_uniq = rll_df['firstTaskGoal'].apply(lambda x: extract_vad_scores(x, vad_df))\n",
    "scores_belong = rll_df['addFirstRelGoal'].apply(lambda x: extract_vad_scores(x, vad_df))\n",
    "final_scores = scores_uniq.tolist() + scores_belong.to_list()\n",
    "rll_df[['valence_score', 'arousal_score', 'dominance_score']] = pd.DataFrame(final_scores)\n",
    "\n",
    "# Step 5: Aggregate scores\n",
    "aggregated_scores = rll_df[['valence_score', 'arousal_score', 'dominance_score']].mean()\n",
    "\n",
    "# Display result\n",
    "print(\"Aggregated VAD Scores:\")\n",
    "print(aggregated_scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LLMs\n",
    "model = 'gemini'\n",
    "path = '/projects/humansVsLLMs/results/3-shot-generated-responses'\n",
    "\n",
    "\n",
    "# Step 1: Read .txt file as vad_df (assuming tab-delimited or space-delimited)\n",
    "vad_df = pd.read_csv(\"/projects/humansVsLLMs/data/VAD/NRC-VAD-Lexicon-v2.1/NRC-VAD-Lexicon-v2.1/NRC-VAD-Lexicon-v2.1.txt\", sep=\"\\t\", on_bad_lines='skip')  # or sep=\"\\t\" depending on the format\n",
    "vad_df.columns = ['term', 'valence', 'arousal', 'dominance']\n",
    "vad_df['term'] = vad_df['term'].str.lower()\n",
    "\n",
    "# Step 2: Read .csv file as llm_df\n",
    "llm_df = pd.read_csv(f\"{path}/{model}_generated_responses.csv\")\n",
    "\n",
    "# Step 3: Define function to extract VAD scores\n",
    "def extract_vad_scores(text, vad_lookup):\n",
    "    if pd.isna(text):\n",
    "        return np.nan, np.nan, np.nan\n",
    "\n",
    "    words = text.lower().split()\n",
    "    matched = vad_lookup[vad_lookup['term'].isin(words)]\n",
    "    \n",
    "    if matched.empty:\n",
    "        return np.nan, np.nan, np.nan\n",
    "    else:\n",
    "        return (\n",
    "            matched['valence'].mean(),\n",
    "            matched['arousal'].mean(),\n",
    "            matched['dominance'].mean()\n",
    "        )\n",
    "\n",
    "# Step 4: Apply the function row-wise\n",
    "scores = llm_df['Response'].apply(lambda x: extract_vad_scores(x, vad_df))\n",
    "llm_df[['valence_score', 'arousal_score', 'dominance_score']] = pd.DataFrame(scores.to_list())\n",
    "\n",
    "# Step 5: Aggregate scores\n",
    "aggregated_scores = llm_df[['valence_score', 'arousal_score', 'dominance_score']].mean()\n",
    "\n",
    "# Display result\n",
    "print(f\"Aggregated VAD Scores for {model}:\")\n",
    "print(aggregated_scores)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "emnlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
