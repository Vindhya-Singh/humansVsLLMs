{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import chain\n",
    "import nltk\n",
    "from nltk import pos_tag, word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import pandas as pd\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For gender wise comparison\n",
    "path = '/projects/humansVsLLMs/data'\n",
    "df = pd.read_csv(f\"{path}/data_leaders_with_demographics_semantics.csv\")  # Replace with your file\n",
    "df = df[~df['GenderIdentity'].isin(['Male', 'Female'])]\n",
    "response_texts_uniqueness = df['firstTaskGoal'].dropna().astype(str).to_list()\n",
    "print(len(response_texts_uniqueness))\n",
    "response_texts_belongingness = df['addFirstRelGoal'].dropna().astype(str).to_list()\n",
    "print(len(response_texts_belongingness))\n",
    "response_texts = response_texts_belongingness + response_texts_uniqueness\n",
    "print(len(response_texts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download required NLTK data (run once)\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_top_nouns_verbs(texts, top_n=20):\n",
    "    # Initialize counters\n",
    "    nouns = defaultdict(int)\n",
    "    verbs = defaultdict(int)\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    \n",
    "    for text in texts:\n",
    "        # Tokenize and POS tag each text\n",
    "        tokens = word_tokenize(text.lower())  # Lowercase for consistency\n",
    "        tagged = pos_tag(tokens)\n",
    "        \n",
    "        for word, tag in tagged:\n",
    "            # Filter out stopwords and non-alphabetic tokens\n",
    "            if word.isalpha() and word not in stop_words:\n",
    "                # Check for nouns (NN, NNS, NNP, NNPS)\n",
    "                if tag.startswith('NN'):\n",
    "                    nouns[word] += 1\n",
    "                # Check for verbs (VB, VBD, VBG, VBN, VBP, VBZ)\n",
    "                elif tag.startswith('VB'):\n",
    "                    verbs[word] += 1\n",
    "    \n",
    "    # Sort and return top N nouns/verbs\n",
    "    top_nouns = sorted(nouns.items(), key=lambda x: x[1], reverse=True)[:top_n]\n",
    "    top_verbs = sorted(verbs.items(), key=lambda x: x[1], reverse=True)[:top_n]\n",
    "    \n",
    "    return top_nouns, top_verbs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RLL usage\n",
    "top_nouns, top_verbs = extract_top_nouns_verbs(response_texts, top_n=20)\n",
    "print(\"Top 20 Nouns:\", top_nouns)\n",
    "print(\"Top 20 Verbs:\", top_verbs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For LLM generated responses\n",
    "path = '/projects/humansVsLLMs/results/3-shot-generated-responses'\n",
    "models = ['cohere', 'deepseek', 'gemini', 'gpt-4o-mini', 'llama', 'mistral', 'qwen']\n",
    "for model in models:\n",
    "    df = pd.read_csv(f'{path}/{model}_generated_responses.csv')\n",
    "    response_texts = df['Response'].to_list()\n",
    "    print(len(response_texts))\n",
    "    top_nouns, top_verbs = extract_top_nouns_verbs(response_texts, top_n=20)\n",
    "    print(f\"{model}: {top_nouns}: {top_verbs}\")\n",
    "    print(\"Top 20 Nouns:\", top_nouns)\n",
    "    print(\"Top 20 Verbs:\", top_verbs)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For age wise comparison\n",
    "path = '/projects/humansVsLLMs/data'\n",
    "df = pd.read_csv(f\"{path}/data_leaders_with_demographics_semantics.csv\")  # Replace with your file\n",
    "df = df[df['Age'].isin(['61',\n",
    " '62',\n",
    " '64',\n",
    " ])]\n",
    "response_texts_uniqueness = df['firstTaskGoal'].dropna().astype(str).to_list()\n",
    "print(len(response_texts_uniqueness))\n",
    "response_texts_belongingness = df['addFirstRelGoal'].dropna().astype(str).to_list()\n",
    "print(len(response_texts_belongingness))\n",
    "response_texts = response_texts_belongingness + response_texts_uniqueness\n",
    "print(len(response_texts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RLL usage\n",
    "top_nouns, top_verbs = extract_top_nouns_verbs(response_texts, top_n=20)\n",
    "print(\"Top 20 Nouns:\", top_nouns)\n",
    "print(\"Top 20 Verbs:\", top_verbs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "emnlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
